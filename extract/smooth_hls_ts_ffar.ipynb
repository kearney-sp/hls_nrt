{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8da3fef-f415-4c09-ab20-9a455524bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /project/cper_neon_aop/conda_envs/hls_nrt_env/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "from hlsstack.hls_funcs.smooth import despike_ts, double_savgol\n",
    "import gc\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457ea626-9bd3-4c0b-b366-a4031276c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/project/cper_neon_aop/hls_nrt/params/co_wss_params')\n",
    "from co_wss_params_smooth import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a9df19-f177-4fdc-831b-25bfb39b0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from importlib import reload\n",
    "#import sys\n",
    "#reload(sys.modules[\"ltar_reno_params_smooth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69266a0-57d4-4f58-8d9f-85d86ee17413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_smooth(ts, dates, despike=True, dat_thresh=None):\n",
    "    ct_valid = sum(~np.isnan(ts))\n",
    "    ct_total = len(ts)\n",
    "    avg_gap = ct_total/ct_valid\n",
    "    if ct_valid > 0:\n",
    "        if avg_gap > 15:\n",
    "            despike = False\n",
    "        if despike:\n",
    "            if dat_thresh is None:\n",
    "                _dat_thresh = np.ptp(ts.values) * 0.10\n",
    "            else:\n",
    "                _dat_thresh = dat_thresh\n",
    "            ts_ds = despike_ts(ts.values, dat_thresh=_dat_thresh, days_thresh=45)\n",
    "        else:\n",
    "            ts_ds = ts.values\n",
    "        if avg_gap > 10:\n",
    "            ts_smooth = double_savgol(ts_ds, double=True, window1_max=7, window2=31, limit=91)\n",
    "        elif avg_gap > 7:\n",
    "             ts_smooth = double_savgol(ts_ds, double=True, window1_max=5, window2=41, limit=91)\n",
    "        elif avg_gap > 5:\n",
    "             ts_smooth = double_savgol(ts_ds, double=True, window1_max=5, window2=51, limit=91)\n",
    "        else:\n",
    "            ts_smooth = double_savgol(ts_ds, double=False, window2=51, limit=91)\n",
    "    else:\n",
    "        ts_smooth = ts\n",
    "    return pd.Series(ts_smooth, ts.index.get_level_values(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5905787-e74a-4db4-8008-bef1e799404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fLIST = glob(inPATH_wc)\n",
    "df = pd.read_csv(inPATH_dat, parse_dates=[date_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3f5f95-f3ad-4ae6-bcf4-f636df295989",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess is not None:\n",
    "    df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4e2427-8b1d-4672-915a-1f0d384a75bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_id</th>\n",
       "      <th>year</th>\n",
       "      <th>tmax_Fall</th>\n",
       "      <th>tmax_Spring</th>\n",
       "      <th>tmax_Summer</th>\n",
       "      <th>tmax_Winter</th>\n",
       "      <th>tmin_Fall</th>\n",
       "      <th>tmin_Spring</th>\n",
       "      <th>tmin_Summer</th>\n",
       "      <th>tmin_Winter</th>\n",
       "      <th>...</th>\n",
       "      <th>COUNTYNS</th>\n",
       "      <th>AFFGEOID</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>2013</td>\n",
       "      <td>18.093000</td>\n",
       "      <td>15.469333</td>\n",
       "      <td>31.385667</td>\n",
       "      <td>6.890667</td>\n",
       "      <td>2.944667</td>\n",
       "      <td>-0.626333</td>\n",
       "      <td>13.051000</td>\n",
       "      <td>-10.074666</td>\n",
       "      <td>...</td>\n",
       "      <td>198122</td>\n",
       "      <td>0500000US08013</td>\n",
       "      <td>8013</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>6</td>\n",
       "      <td>1881290197</td>\n",
       "      <td>36512644</td>\n",
       "      <td>-105.083690</td>\n",
       "      <td>40.215500</td>\n",
       "      <td>2013-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>2014</td>\n",
       "      <td>19.764000</td>\n",
       "      <td>17.866667</td>\n",
       "      <td>30.010334</td>\n",
       "      <td>6.795667</td>\n",
       "      <td>2.328000</td>\n",
       "      <td>1.292333</td>\n",
       "      <td>12.485333</td>\n",
       "      <td>-8.753333</td>\n",
       "      <td>...</td>\n",
       "      <td>198122</td>\n",
       "      <td>0500000US08013</td>\n",
       "      <td>8013</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>6</td>\n",
       "      <td>1881290197</td>\n",
       "      <td>36512644</td>\n",
       "      <td>-105.106560</td>\n",
       "      <td>40.218361</td>\n",
       "      <td>2014-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2015</td>\n",
       "      <td>20.734333</td>\n",
       "      <td>17.272666</td>\n",
       "      <td>30.867000</td>\n",
       "      <td>8.573000</td>\n",
       "      <td>4.229667</td>\n",
       "      <td>1.912333</td>\n",
       "      <td>13.297667</td>\n",
       "      <td>-6.749000</td>\n",
       "      <td>...</td>\n",
       "      <td>198122</td>\n",
       "      <td>0500000US08013</td>\n",
       "      <td>8013</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>6</td>\n",
       "      <td>1881290197</td>\n",
       "      <td>36512644</td>\n",
       "      <td>-105.104670</td>\n",
       "      <td>40.217800</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>2016</td>\n",
       "      <td>22.227500</td>\n",
       "      <td>16.650000</td>\n",
       "      <td>31.645334</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>3.820667</td>\n",
       "      <td>1.422333</td>\n",
       "      <td>13.247667</td>\n",
       "      <td>-7.922000</td>\n",
       "      <td>...</td>\n",
       "      <td>198122</td>\n",
       "      <td>0500000US08013</td>\n",
       "      <td>8013</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>6</td>\n",
       "      <td>1881290197</td>\n",
       "      <td>36512644</td>\n",
       "      <td>-105.106776</td>\n",
       "      <td>40.218197</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>18.544333</td>\n",
       "      <td>18.427667</td>\n",
       "      <td>30.664000</td>\n",
       "      <td>7.450000</td>\n",
       "      <td>2.399667</td>\n",
       "      <td>1.957667</td>\n",
       "      <td>13.454000</td>\n",
       "      <td>-8.104000</td>\n",
       "      <td>...</td>\n",
       "      <td>198122</td>\n",
       "      <td>0500000US08013</td>\n",
       "      <td>8013</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>6</td>\n",
       "      <td>1881290197</td>\n",
       "      <td>36512644</td>\n",
       "      <td>-105.103600</td>\n",
       "      <td>40.217700</td>\n",
       "      <td>2018-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plot_id  year  tmax_Fall  tmax_Spring  tmax_Summer  tmax_Winter  tmin_Fall  \\\n",
       "0       90  2013  18.093000    15.469333    31.385667     6.890667   2.944667   \n",
       "1       19  2014  19.764000    17.866667    30.010334     6.795667   2.328000   \n",
       "2       19  2015  20.734333    17.272666    30.867000     8.573000   4.229667   \n",
       "3       19  2016  22.227500    16.650000    31.645334     7.930000   3.820667   \n",
       "4       19  2018  18.544333    18.427667    30.664000     7.450000   2.399667   \n",
       "\n",
       "   tmin_Spring  tmin_Summer  tmin_Winter  ...  COUNTYNS        AFFGEOID  \\\n",
       "0    -0.626333    13.051000   -10.074666  ...    198122  0500000US08013   \n",
       "1     1.292333    12.485333    -8.753333  ...    198122  0500000US08013   \n",
       "2     1.912333    13.297667    -6.749000  ...    198122  0500000US08013   \n",
       "3     1.422333    13.247667    -7.922000  ...    198122  0500000US08013   \n",
       "4     1.957667    13.454000    -8.104000  ...    198122  0500000US08013   \n",
       "\n",
       "   GEOID     NAME  LSAD       ALAND    AWATER   Longitude   Latitude  \\\n",
       "0   8013  Boulder     6  1881290197  36512644 -105.083690  40.215500   \n",
       "1   8013  Boulder     6  1881290197  36512644 -105.106560  40.218361   \n",
       "2   8013  Boulder     6  1881290197  36512644 -105.104670  40.217800   \n",
       "3   8013  Boulder     6  1881290197  36512644 -105.106776  40.218197   \n",
       "4   8013  Boulder     6  1881290197  36512644 -105.103600  40.217700   \n",
       "\n",
       "        date  \n",
       "0 2013-08-01  \n",
       "1 2014-08-01  \n",
       "2 2015-08-01  \n",
       "3 2016-08-01  \n",
       "4 2018-08-01  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afd8d80-d54d-492d-8cd5-27ec3164d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf825c0b-cb66-4847-a9ff-6bf25c5b5837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 135.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 289.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 410.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 406.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 398.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 370.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 163.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 165.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 141.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 145.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 188.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 225.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 247.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 236.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 143.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 144.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "Smoothing vegetation indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 183.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing individual bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 204.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m fLIST_yr \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m fLIST \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(yr) \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(x)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# combine all individual tile files into one dataframe\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_yr \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfLIST_yr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# rename columns to match ground data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df_yr \u001b[38;5;241m=\u001b[39m df_yr\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: date_col,\n\u001b[1;32m     12\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlot\u001b[39m\u001b[38;5;124m'\u001b[39m: id_col})\n",
      "File \u001b[0;32m/project/cper_neon_aop/conda_envs/hls_nrt_env/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/cper_neon_aop/conda_envs/hls_nrt_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/project/cper_neon_aop/conda_envs/hls_nrt_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:404\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    401\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "for yr in df[date_col].dt.year.unique():\n",
    "    print(yr)\n",
    "\n",
    "    # get list of files that match year based on path\n",
    "    fLIST_yr = [x for x in fLIST if str(yr) in os.path.basename(x).split('_')]\n",
    "\n",
    "    # combine all individual tile files into one dataframe\n",
    "    df_yr = pd.concat([pd.read_csv(x, parse_dates=[1]) for x in fLIST_yr])\n",
    "    \n",
    "    # rename columns to match ground data\n",
    "    df_yr = df_yr.rename(columns={'time': date_col,\n",
    "                                  'Plot': id_col})\n",
    "    \n",
    "    # convert date to datetime\n",
    "    df_yr[date_col] = pd.to_datetime(df_yr[date_col])\n",
    "    \n",
    "    # remove all non-plot data\n",
    "    #df_yr = df_yr[df_yr[id_col] != 'UNK']\n",
    "    \n",
    "    # remove any dates where bands are negative\n",
    "    df_yr = df_yr[~((df_yr[band_list] < 0).any(axis=1))]\n",
    "\n",
    "    # drop any duplicates by taking mean for each plot and date (might exist e.g., from plot on edge of tile during extraction)\n",
    "    df_yr = df_yr.groupby([id_col, date_col]).mean().reset_index()\n",
    "    \n",
    "    # get missing dates for gap-filling\n",
    "    dates_missing = [x for x in pd.date_range(df_yr[date_col].min(), df_yr[date_col].max()).date if x not in df_yr[date_col].dt.date.unique()]\n",
    "    \n",
    "    # convert missing dates to a dataframe for combining with veg index data\n",
    "    df_missing = pd.DataFrame({\n",
    "        id_col: list(chain.from_iterable([list(np.repeat(x, len(dates_missing))) for x in df_yr[id_col].unique()])),\n",
    "        date_col: list(chain.from_iterable(dates_missing for x in df_yr[id_col].unique()))})\n",
    "    \n",
    "    df_missing[date_col] = pd.to_datetime(df_missing[date_col])\n",
    "    \n",
    "    # combine into one dataframe for gapfilling\n",
    "    df_yr_ts = pd.concat([df_yr, df_missing]).sort_values([id_col, date_col])\n",
    "    \n",
    "    # apply Bolton mask to extracted values\n",
    "    if mask_bolton_by_id:\n",
    "        ps_bolton = df_yr_ts.groupby(id_col).progress_apply(lambda x: bolton_mask_np(x['BLUE'], x['SWIR2']))\n",
    "        df_yr_ts.loc[df_yr_ts[ps_bolton.droplevel(0) == 1.0].index, list(veg_dict.keys()) + band_list] = np.nan\n",
    "    \n",
    "    # smooth all vegetation indices to gapfill\n",
    "    print('Smoothing vegetation indices')\n",
    "    for vegidx in tqdm(veg_list):\n",
    "        #df_yr_ts[vegidx + '_smooth'] = df_yr_ts.groupby(id_col)[vegidx].transform(lambda x: double_savgol(x.values))\n",
    "        vals_smooth_yr = df_yr_ts.groupby(id_col).apply(lambda x: adapt_smooth(x[vegidx], pd.to_datetime(x[date_col])))\n",
    "        if vals_smooth_yr.index.nlevels > 1:\n",
    "            df_yr_ts[vegidx + '_smooth'] = vals_smooth_yr.droplevel(list(np.arange(vals_smooth_yr.index.nlevels-1)))\n",
    "        else:\n",
    "            df_yr_ts[vegidx + '_smooth'] = vals_smooth_yr.values.squeeze()\n",
    "    print('Smoothing individual bands')\n",
    "    for band in tqdm(band_list):\n",
    "        #df_yr_ts[band + '_smooth'] = df_yr_ts.groupby(id_col)[band].transform(lambda x: double_savgol(x.values))\n",
    "        vals_smooth_yr = df_yr_ts.groupby(id_col).apply(lambda x: adapt_smooth(x[band], pd.to_datetime(x[date_col])))\n",
    "        if vals_smooth_yr.index.nlevels > 1:\n",
    "            df_yr_ts[band + '_smooth'] = vals_smooth_yr.droplevel(list(np.arange(vals_smooth_yr.index.nlevels-1)))\n",
    "        else:\n",
    "            df_yr_ts[band + '_smooth'] = vals_smooth_yr.values.squeeze()\n",
    "    \n",
    "    # rename smoothed columns and drop originals\n",
    "    df_yr_ts = df_yr_ts.drop(columns=veg_list + band_list)\n",
    "    col_rename_dict = {c: re.sub('_smooth', '', c) for c in df_yr_ts.columns if '_smooth' in c}\n",
    "    df_yr_ts = df_yr_ts.rename(columns=col_rename_dict)\n",
    "\n",
    "    # merge with the ground data\n",
    "    df_out_yr = pd.merge(df[df[date_col].dt.year == yr], \n",
    "                         df_yr_ts[[id_col, date_col] + veg_list + band_list], \n",
    "                         on=[id_col, date_col],\n",
    "                         how='left')\n",
    "\n",
    "    # create or append to final output\n",
    "    if df_out is not None:\n",
    "        # merge with existing ouptput dataset\n",
    "        df_out = pd.concat([df_out, df_out_yr])\n",
    "    else:\n",
    "        # create output dataset\n",
    "        df_out = df_out_yr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9464d68-8412-4e9c-98a4-047d2533eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_id</th>\n",
       "      <th>year</th>\n",
       "      <th>tmax_Fall</th>\n",
       "      <th>tmax_Spring</th>\n",
       "      <th>tmax_Summer</th>\n",
       "      <th>tmax_Winter</th>\n",
       "      <th>tmin_Fall</th>\n",
       "      <th>tmin_Spring</th>\n",
       "      <th>tmin_Summer</th>\n",
       "      <th>tmin_Winter</th>\n",
       "      <th>...</th>\n",
       "      <th>BAI_146</th>\n",
       "      <th>BAI_236</th>\n",
       "      <th>BAI_246</th>\n",
       "      <th>BAI_346</th>\n",
       "      <th>BLUE</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>RED</th>\n",
       "      <th>NIR1</th>\n",
       "      <th>SWIR1</th>\n",
       "      <th>SWIR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>2013</td>\n",
       "      <td>18.093000</td>\n",
       "      <td>15.469333</td>\n",
       "      <td>31.385667</td>\n",
       "      <td>6.890667</td>\n",
       "      <td>2.944667</td>\n",
       "      <td>-0.626333</td>\n",
       "      <td>13.051000</td>\n",
       "      <td>-10.074666</td>\n",
       "      <td>...</td>\n",
       "      <td>86.980117</td>\n",
       "      <td>198.244553</td>\n",
       "      <td>84.433554</td>\n",
       "      <td>77.98036</td>\n",
       "      <td>398.650372</td>\n",
       "      <td>705.335429</td>\n",
       "      <td>604.349792</td>\n",
       "      <td>3937.752002</td>\n",
       "      <td>1961.913096</td>\n",
       "      <td>1074.808703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.437667</td>\n",
       "      <td>14.070667</td>\n",
       "      <td>29.778334</td>\n",
       "      <td>5.885667</td>\n",
       "      <td>3.721000</td>\n",
       "      <td>-0.048000</td>\n",
       "      <td>14.073667</td>\n",
       "      <td>-8.409000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.525667</td>\n",
       "      <td>14.217333</td>\n",
       "      <td>30.109333</td>\n",
       "      <td>5.803667</td>\n",
       "      <td>3.550667</td>\n",
       "      <td>-0.092000</td>\n",
       "      <td>14.091667</td>\n",
       "      <td>-8.854667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.941000</td>\n",
       "      <td>14.422334</td>\n",
       "      <td>30.668666</td>\n",
       "      <td>5.902000</td>\n",
       "      <td>2.449333</td>\n",
       "      <td>-0.891333</td>\n",
       "      <td>13.485333</td>\n",
       "      <td>-10.618666</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>2013</td>\n",
       "      <td>17.532000</td>\n",
       "      <td>14.942666</td>\n",
       "      <td>30.469334</td>\n",
       "      <td>6.007333</td>\n",
       "      <td>2.127333</td>\n",
       "      <td>-1.608333</td>\n",
       "      <td>12.058667</td>\n",
       "      <td>-11.162000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   plot_id  year  tmax_Fall  tmax_Spring  tmax_Summer  tmax_Winter  tmin_Fall  \\\n",
       "0       90  2013  18.093000    15.469333    31.385667     6.890667   2.944667   \n",
       "1       77  2013  17.437667    14.070667    29.778334     5.885667   3.721000   \n",
       "2       78  2013  17.525667    14.217333    30.109333     5.803667   3.550667   \n",
       "3       79  2013  17.941000    14.422334    30.668666     5.902000   2.449333   \n",
       "4      106  2013  17.532000    14.942666    30.469334     6.007333   2.127333   \n",
       "\n",
       "   tmin_Spring  tmin_Summer  tmin_Winter  ...    BAI_146     BAI_236  \\\n",
       "0    -0.626333    13.051000   -10.074666  ...  86.980117  198.244553   \n",
       "1    -0.048000    14.073667    -8.409000  ...        NaN         NaN   \n",
       "2    -0.092000    14.091667    -8.854667  ...        NaN         NaN   \n",
       "3    -0.891333    13.485333   -10.618666  ...        NaN         NaN   \n",
       "4    -1.608333    12.058667   -11.162000  ...        NaN         NaN   \n",
       "\n",
       "     BAI_246   BAI_346        BLUE       GREEN         RED         NIR1  \\\n",
       "0  84.433554  77.98036  398.650372  705.335429  604.349792  3937.752002   \n",
       "1        NaN       NaN         NaN         NaN         NaN          NaN   \n",
       "2        NaN       NaN         NaN         NaN         NaN          NaN   \n",
       "3        NaN       NaN         NaN         NaN         NaN          NaN   \n",
       "4        NaN       NaN         NaN         NaN         NaN          NaN   \n",
       "\n",
       "         SWIR1        SWIR2  \n",
       "0  1961.913096  1074.808703  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06657a-d27e-481d-9f80-30e7cfcc898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for any missing data\n",
    "df_out[df_out['NDVI'].isnull()].sort_values(id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5de00a1-8b2d-4486-9698-2700d3bef9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Block_name</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>Ranch</th>\n",
       "      <th>Year</th>\n",
       "      <th>Low.reading_mean</th>\n",
       "      <th>Low.reading_sd</th>\n",
       "      <th>High.reading_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>BAI_146</th>\n",
       "      <th>BAI_236</th>\n",
       "      <th>BAI_246</th>\n",
       "      <th>BAI_346</th>\n",
       "      <th>BLUE</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>RED</th>\n",
       "      <th>NIR1</th>\n",
       "      <th>SWIR1</th>\n",
       "      <th>SWIR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Block_name, Treatment, Date, Site, Ranch, Year, Low.reading_mean, Low.reading_sd, High.reading_mean, High.reading_sd, Low.rounded_5_mean, Low.rounded_5_sd, Low.rounded_10_mean, Low.rounded_10_sd, High.rounded_5_mean, High.rounded_5_sd, High.rounded_10_mean, High.rounded_10_sd, Sample_ID_vor, mean_biomass, sd_biomass, Sample_ID_bio, X_coord, Y_coord, ID, Block_Id, NDVI, DFI, NDTI, SATVI, NDII7, SAVI, RDVI, MTVI1, NCI, NDCI, PSRI, NDWI, EVI, TCBI, TCGI, TCWI, BAI_126, BAI_136, BAI_146, BAI_236, BAI_246, BAI_346, BLUE, GREEN, RED, NIR1, SWIR1, SWIR2]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 55 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for any duplicated ID's\n",
    "df_out[df_out.duplicated(subset=[id_col, date_col], keep=False)].sort_values(id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf5bd6a-1b04-45e8-a407-e361c82a72a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Block_name</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>Ranch</th>\n",
       "      <th>Year</th>\n",
       "      <th>Low.reading_mean</th>\n",
       "      <th>Low.reading_sd</th>\n",
       "      <th>High.reading_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>BAI_146</th>\n",
       "      <th>BAI_236</th>\n",
       "      <th>BAI_246</th>\n",
       "      <th>BAI_346</th>\n",
       "      <th>BLUE</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>RED</th>\n",
       "      <th>NIR1</th>\n",
       "      <th>SWIR1</th>\n",
       "      <th>SWIR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Block_name, Treatment, Date, Site, Ranch, Year, Low.reading_mean, Low.reading_sd, High.reading_mean, High.reading_sd, Low.rounded_5_mean, Low.rounded_5_sd, Low.rounded_10_mean, Low.rounded_10_sd, High.rounded_5_mean, High.rounded_5_sd, High.rounded_10_mean, High.rounded_10_sd, Sample_ID_vor, mean_biomass, sd_biomass, Sample_ID_bio, X_coord, Y_coord, ID, Block_Id, NDVI, DFI, NDTI, SATVI, NDII7, SAVI, RDVI, MTVI1, NCI, NDCI, PSRI, NDWI, EVI, TCBI, TCGI, TCWI, BAI_126, BAI_136, BAI_146, BAI_236, BAI_246, BAI_346, BLUE, GREEN, RED, NIR1, SWIR1, SWIR2]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for any duplicated ID's\n",
    "df_out[df_out.duplicated(subset=[id_col, date_col, 'NDVI'], keep=False)].sort_values(id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265f5a71-0051-40ff-9021-80723e1fb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean or drop duplicated ID's\n",
    "df_out = df_out.drop_duplicates(subset=[id_col, date_col], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "042e8034-f4da-414a-aedd-9bd85c50e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(outPATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e111d2-b527-4621-b4e6-9dfee483d335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_nrt_env",
   "language": "python",
   "name": "hls_nrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
