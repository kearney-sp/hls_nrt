{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd9d90-936d-4506-aecb-b9cff2af9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as riox\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from src.hls_funcs.masks import shp2mask\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33b492-5fca-4f0f-8df5-f1e03ac2f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'cper'\n",
    "yr = 2022\n",
    "\n",
    "cluster_loc = 'hpc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad895df-3efc-400b-80fa-fddea53e77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_loc == 'local':\n",
    "    os.chdir(wkDIR)\n",
    "    print('   setting up Local cluster...')\n",
    "    from dask.distributed import LocalCluster, Client\n",
    "    import dask\n",
    "    cluster = LocalCluster(n_workers=8, threads_per_worker=2)\n",
    "    client = Client(cluster)\n",
    "    display(client)\n",
    "    inDIR = 'data/'\n",
    "    hlsDIR = 'data/hls_nrt/'\n",
    "elif cluster_loc == 'hpc':\n",
    "    from dask.distributed import LocalCluster, Client\n",
    "    import dask_jobqueue as jq\n",
    "    import dask\n",
    "    from jupyter_server import serverapp\n",
    "    wkDIR = '/project/cper_neon_aop/hls_nrt/'\n",
    "    inDIR = '/90daydata/cper_neon_aop/hls_nrt/'\n",
    "    hlsDIR = inDIR\n",
    "    os.chdir(wkDIR)\n",
    "    # get the server address for porting\n",
    "    try:\n",
    "        jupServer = [x for x in serverapp.list_running_servers()][0]\n",
    "    except IndexError:\n",
    "        # manually copy/paste the server address\n",
    "        jupServer = {'base_url': '/node/ceres19-compute-98-eth.scinet.local/17710/'}\n",
    "    print('   setting up cluster on HPC...')\n",
    "    dask.config.set({'distributed.dashboard.link': jupServer['base_url'] + 'proxy/{port}/status'})\n",
    "    partition='short',#'short','debug', 'mem', 'mem-low',\n",
    "    num_processes = 4\n",
    "    num_threads_per_processes = 2\n",
    "    mem = 2.5*num_processes*num_threads_per_processes\n",
    "    n_cores_per_job = num_processes*num_threads_per_processes\n",
    "    clust = jq.SLURMCluster(queue=partition,\n",
    "                            processes=num_processes,\n",
    "                            cores=n_cores_per_job,\n",
    "                            memory=str(mem)+'GB',\n",
    "                            interface='ib0',\n",
    "                            #interface='enp24s0f0',\n",
    "                            local_directory='$TMPDIR',\n",
    "                            death_timeout=30,\n",
    "                            walltime='02:00:00',\n",
    "                            job_extra=[\"--output=/dev/null\",\"--error=/dev/null\"])\n",
    "    client=Client(clust)\n",
    "    #Scale Cluster \n",
    "    num_jobs=16\n",
    "    clust.scale(jobs=num_jobs)\n",
    "    try:\n",
    "        client.wait_for_workers(n_workers=num_jobs*num_processes, timeout=60)\n",
    "    except dask.distributed.TimeoutError as e:\n",
    "        print(str(num_jobs*num_processes) + ' workers not available. Continuing with available workers.')\n",
    "        #print(e)\n",
    "        pass\n",
    "    display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a530de-4a98-4bf6-b10e-c5929fa6d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = riox.open_rasterio(os.path.join(inDIR, 'gcloud', 'hls_' + prefix + '_' + str(yr) + '_gcloud.nc'), masked=True)\n",
    "ds_ndvi_lta = riox.open_rasterio(os.path.join(inDIR, 'ee_lta', prefix + '_ee_ndvi_landsat_wkly_lta.nc'), masked=True)\n",
    "ds_ndvi_lta['date'] = [datetime.strptime(re.sub('2020', '2099', str(x)),'%Y-%m-%d %H:%M:%S') for x in ds_ndvi_lta['date'].values]\n",
    "#ds_ndvi_lta['date'] = ds_ndvi_lta['date'].dt.date\n",
    "ds_ndvi_lta = ds_ndvi_lta.reindex({'y': ds.y, 'x': ds.x}, method='nearest', tolerance=30)#.isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47b214-bc22-4821-a46a-beab41858427",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prefix == 'cper':\n",
    "    cper_f = 'data/ground/cper_pastures_2017_dissolved.shp'\n",
    "    cper = gpd.read_file(cper_f).to_crs(ds.rio.crs.to_epsg())\n",
    "    cper_info = cper[['Pasture', 'geometry']].reset_index(drop=True).reset_index().rename(columns={'index': 'id'})\n",
    "    past_dict = {row.id+1: row.Pasture for _, row in cper_info.iterrows()}\n",
    "    past_dict[0] = 'UNK'\n",
    "    cper_mask_shp = [(row.geometry, row.id+1) for _, row in cper_info.iterrows()]\n",
    "    cper_mask = shp2mask(shp=cper_mask_shp, \n",
    "                         transform=ds.rio.transform(), \n",
    "                         outshape=ds['NDVI'].shape[1:], \n",
    "                         xr_object=ds['NDVI'])\n",
    "    past_mask = np.array([past_dict[i] for i in cper_mask.values.flatten()]).reshape(cper_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9538e-db03-4656-b31c-abf4600b63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign(Pasture=(['y', 'x'], past_mask)).chunk({'y': 50, 'x': 50})\n",
    "ds = ds.set_coords('Pasture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88637c55-0de8-4706-9a4d-07278f1384e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_ndvi_lta['date'] = pd.to_datetime(ds_ndvi_lta['date']) + timedelta(days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54bb8c-0b6a-4e5f-b1a7-6ea8aa2b53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndvi_lta = ds_ndvi_lta.groupby(ds['Pasture']).mean(dim='stacked_y_x').to_dataframe().reset_index().drop(columns='spatial_ref')\n",
    "df_ndvi_lta['Year'] = '30-yr avg.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e3700-4eaf-4474-bf85-f06b8a715f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_list = [2020, 2021, 2022]\n",
    "for idx, yr_i in enumerate(tqdm(yr_list)):\n",
    "    mon_day = (8 - datetime(2020, 1, 1).weekday()) % 7\n",
    "    yr_dates_tmp = [datetime(yr_i, 1, mon_day) + timedelta(weeks=w) for w in range(52)]\n",
    "    if yr_i == yr:\n",
    "        ds_i = ds\n",
    "    else:\n",
    "        ds_i = riox.open_rasterio(os.path.join(inDIR, 'gcloud', 'hls_' + prefix + '_' + str(yr_i) + '_gcloud.nc'), masked=True)\n",
    "    ds_i['date'] = [datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S') for x in ds_i['date'].values]\n",
    "    \n",
    "    if yr_i != yr_list[-1]:\n",
    "        ds_ndvi_yr_wkly = ds_i['NDVI'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        ds_bm_yr_wkly = ds_i['Biomass'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        ds_bare_yr_wkly = ds_i['BARE'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        ds_sd_yr_wkly = ds_i['SD'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        ds_green_yr_wkly = ds_i['GREEN'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        ds_litt_yr_wkly = ds_i['LITT'].sel(date=yr_dates_tmp, method='nearest', tolerance=timedelta(days=1), drop=True)\n",
    "        df_yr_wkly = xr.merge([ds_ndvi_yr_wkly,\n",
    "                               ds_bm_yr_wkly,\n",
    "                               ds_bare_yr_wkly,\n",
    "                               ds_sd_yr_wkly,\n",
    "                               ds_green_yr_wkly,\n",
    "                               ds_litt_yr_wkly]).groupby(\n",
    "            ds['Pasture']).mean(\n",
    "            dim='stacked_y_x').to_dataframe().reset_index().drop(\n",
    "            columns='spatial_ref')\n",
    "    else:\n",
    "        df_yr_wkly = xr.merge([ds_i['NDVI'],\n",
    "                           ds_i['Biomass'],\n",
    "                           ds_i['BARE'],\n",
    "                           ds_i['SD'],\n",
    "                           ds_i['GREEN'],\n",
    "                           ds_i['LITT']]).groupby(\n",
    "        ds['Pasture']).mean(\n",
    "        dim='stacked_y_x').to_dataframe().reset_index().drop(\n",
    "        columns='spatial_ref')\n",
    "    df_yr_wkly['Year'] = str(yr_i)\n",
    "    \n",
    "    if idx == 0:\n",
    "        df_out = df_yr_wkly.copy()\n",
    "    else:\n",
    "        df_out = pd.concat([df_out, df_yr_wkly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923f9fa-59ef-4340-b1df-ca7b41e5e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.concat([df_ndvi_lta, df_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d377b3-11ed-4304-ba9c-ec9dc2633a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_aoi = df_out.groupby('date').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ade544-5922-4c5b-99ba-a045e209cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_aoi['Pasture'] = prefix\n",
    "df_out_aoi['Year'] = df_out_aoi['date'].dt.isocalendar().year.transform(lambda x: '30-yr avg.' if x == 2099 else str(x))\n",
    "df_out = pd.concat([df_out, df_out_aoi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb683f4-fa88-402e-a413-a3cb3e78d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135eaa63-14cb-4182-adbd-de8f36c83a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['cov_sum'] = df_out[['BARE', 'SD', 'GREEN', 'LITT']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5184c9b-b451-46e5-bb0a-d7a0230ea9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure pasture-scale means of fractional cover sum to 1\n",
    "for c in tqdm(['BARE', 'SD', 'GREEN', 'LITT']):\n",
    "    df_out[c] = df_out.groupby(['date', 'Year', 'Pasture']).apply(lambda x: x[c]/x['cov_sum']).reset_index(level=[0, 1, 2])[0]\n",
    "#df_out = df_out.drop(columns=['cov_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea643c8a-ba90-42cc-a5b0-9a3b7cc6f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.drop(columns=['cov_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c69b43-6791-4898-b694-8263b80258db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[['NDVI', \n",
    "        'Biomass',\n",
    "        'BARE',\n",
    "        'SD', \n",
    "        'GREEN',\n",
    "        'LITT']] = df_out.transform({'NDVI': lambda x: np.round(x, 3),\n",
    "                  'Biomass': lambda x: np.round(x, 0),\n",
    "                  'BARE': lambda x: np.round(x * 100, 1),\n",
    "                  'SD': lambda x: np.round(x * 100, 1),\n",
    "                  'GREEN': lambda x: np.round(x * 100, 1),\n",
    "                  'LITT': lambda x: np.round(x * 100, 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3cca3-f211-40ba-837c-32fcca9f0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(os.path.join(inDIR, 'gcloud', 'hls_' + prefix + '_means.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a100a1-d467-424d-bc22-0fb54c92237d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_nrt_env",
   "language": "python",
   "name": "hls_nrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
